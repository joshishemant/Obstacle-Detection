{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Obstacle_Detection_And _Path_Finder .ipynb","provenance":[{"file_id":"https://github.com/Nisarg-1406/Obstacle-Detection-on-the-Moving-Video/blob/main/Obstacle_Detection_On_Person.ipynb","timestamp":1620981419379}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"dHbHTiskmWo7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623475129613,"user_tz":-330,"elapsed":42720,"user":{"displayName":"Rohan Juneja","photoUrl":"","userId":"13736608838607211922"}},"outputId":"392deb01-1962-4e43-aa2f-3ce7292a0d68"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P93yYOZj6VEq","executionInfo":{"status":"ok","timestamp":1623475136006,"user_tz":-330,"elapsed":2440,"user":{"displayName":"Rohan Juneja","photoUrl":"","userId":"13736608838607211922"}}},"source":["import os\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","import sys\n","import time"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"dKFD-9gz6drS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623475164018,"user_tz":-330,"elapsed":20767,"user":{"displayName":"Rohan Juneja","photoUrl":"","userId":"13736608838607211922"}},"outputId":"bf169555-377a-403c-be2f-76559feedad3"},"source":["!git clone https://github.com/tensorflow/models.git\n","!apt-get -qq install libprotobuf-java protobuf-compiler\n","!protoc ./models/research/object_detection/protos/string_int_label_map.proto --python_out=.\n","!cp -R models/research/object_detection/ object_detection/\n","!rm -rf models\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","from collections import defaultdict\n","from io import StringIO\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'models'...\n","remote: Enumerating objects: 58271, done.\u001b[K\n","remote: Counting objects: 100% (56/56), done.\u001b[K\n","remote: Compressing objects: 100% (56/56), done.\u001b[K\n","remote: Total 58271 (delta 22), reused 34 (delta 0), pack-reused 58215\u001b[K\n","Receiving objects: 100% (58271/58271), 572.99 MiB | 38.29 MiB/s, done.\n","Resolving deltas: 100% (40458/40458), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qaRg-RFM6lkM","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1623475660329,"user_tz":-330,"elapsed":494818,"user":{"displayName":"Rohan Juneja","photoUrl":"","userId":"13736608838607211922"}},"outputId":"eb77ed74-e183-4ed3-a515-8b240be168d0"},"source":["from google.colab import files\n","def upload_files():\n","  from google.colab import files\n","  uploaded = files.upload()\n","  for k, v in uploaded.items():\n","    open(k, 'wb').write(v)\n","  return list(uploaded.keys())\n","upload_files()"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-2c4e9957-ef1f-4d75-a11d-4c7995f8d545\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-2c4e9957-ef1f-4d75-a11d-4c7995f8d545\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving New_York_Street.mp4 to New_York_Street.mp4\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['New_York_Street.mp4']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"_xcOexUL6xZa","executionInfo":{"status":"ok","timestamp":1623475665999,"user_tz":-330,"elapsed":5692,"user":{"displayName":"Rohan Juneja","photoUrl":"","userId":"13736608838607211922"}}},"source":["MODEL_NAME = 'faster_rcnn_inception_v2_coco_2018_01_28'\n","#MODEL_NAME = 'ssd_inception_v2_coco_2017_11_17'\n","MODEL_FILE = MODEL_NAME + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n","PATH_TO_LABELS = os.path.join('object_detection/data', 'mscoco_label_map.pbtxt')\n","NUM_CLASSES = 10\n","opener = urllib.request.URLopener()\n","opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","tar_file = tarfile.open(MODEL_FILE)\n","for file in tar_file.getmembers():\n","  file_name = os.path.basename(file.name)\n","  if 'frozen_inference_graph.pb' in file_name:\n","    tar_file.extract(file, os.getcwd())\n","\n","#created the detection graph for the location - \n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","  od_graph_def = tf.compat.v1.GraphDef()\n","  with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","    serialized_graph = fid.read()\n","    od_graph_def.ParseFromString(serialized_graph)\n","    tf.import_graph_def(od_graph_def, name='')\n","    \n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"w6spFXlJH4c_","executionInfo":{"status":"ok","timestamp":1623475666011,"user_tz":-330,"elapsed":26,"user":{"displayName":"Rohan Juneja","photoUrl":"","userId":"13736608838607211922"}}},"source":["def region_of_interest(img, vertices):\n","    mask = np.zeros_like(img)   \n","    if len(img.shape) > 2:\n","        channel_count = img.shape[2]\n","        ignore_mask_color = (255,) * channel_count\n","    else:\n","        ignore_mask_color = 255   \n","    cv2.fillPoly(mask, vertices, ignore_mask_color)\n","    masked_image = cv2.bitwise_and(img, mask)\n","    return masked_image\n","    cv2.imshow(\"Image\",masked_image)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"fughcmvgVI10","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623475884341,"user_tz":-330,"elapsed":412,"user":{"displayName":"Rohan Juneja","photoUrl":"","userId":"13736608838607211922"}},"outputId":"490d3f8c-d333-4452-9f7a-66fa6b346d89"},"source":["video = cv2.VideoCapture(\"New_York_Street.mp4\")\n","fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","frame_width = int(video.get(3))\n","frame_height = int(video.get(4))\n","\n","out = cv2.VideoWriter('/content/drive/My Drive/New_York_Street.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 90 , (frame_width,frame_height))\n","print (frame_width)\n","try:\n","  \n","  while(video.isOpened()):\n","      #defining the bouandary of the boxes - \n","      ret, frame = video.read()\n","      stime = time.time()\n","      objects = []\n","      class_str = \"\"\n","      frame_width = frame.shape[0]\n","      frame_height = frame.shape[1]\n","      rows, cols = frame.shape[:2]\n","      left_boundary = [int(cols*0.40), int(rows*0.95)]\n","      left_boundary_top = [int(cols*0.40), int(rows*0.20)]\n","      right_boundary = [int(cols*0.60), int(rows*0.95)]\n","      right_boundary_top = [int(cols*0.60), int(rows*0.20)]\n","      bottom_left  = [int(cols*0.20), int(rows*0.95)]\n","      top_left     = [int(cols*0.20), int(rows*0.20)]\n","      bottom_right = [int(cols*0.80), int(rows*0.95)]\n","      top_right    = [int(cols*0.80), int(rows*0.20)]\n","      vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n","      cv2.line(frame,tuple(bottom_left),tuple(bottom_right), (255, 0, 0), 5)\n","      cv2.line(frame,tuple(bottom_right),tuple(top_right), (255, 0, 0), 5)\n","      cv2.line(frame,tuple(top_left),tuple(bottom_left), (255, 0, 0), 5)\n","      cv2.line(frame,tuple(top_left),tuple(top_right), (255, 0, 0), 5)\n","      copied = np.copy(frame)\n","      interested=region_of_interest(copied,vertices)\n","      frame_expanded = np.expand_dims(interested, axis=0)\n","\n","      (boxes, scores, classes, num) = sess.run(\n","          [detection_boxes, detection_scores, detection_classes, num_detections],\n","          feed_dict={image_tensor: frame_expanded})\n","      vis_util.visualize_boxes_and_labels_on_image_array(\n","          frame,\n","          np.squeeze(boxes),\n","          np.squeeze(classes).astype(np.int32),\n","          np.squeeze(scores),\n","          category_index,\n","          use_normalized_coordinates=True,\n","          line_thickness=8,\n","          min_score_thresh=0.78)\n","      print(frame_width,frame_height)\n","      ymin = int((boxes[0][0][0]*frame_width))\n","      xmin = int((boxes[0][0][1]*frame_height))\n","      ymax = int((boxes[0][0][2]*frame_width))\n","      xmax = int((boxes[0][0][3]*frame_height))\n","      Result = np.array(frame[ymin:ymax,xmin:xmax])\n","\n","      ymin_str='y min  = %.2f '%(ymin)\n","      ymax_str='y max  = %.2f '%(ymax)\n","      xmin_str='x min  = %.2f '%(xmin)\n","      xmax_str='x max  = %.2f '%(xmax)\n","\n","      cv2.putText(frame,ymin_str, (50, 50),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n","      cv2.putText(frame,ymax_str, (50, 70),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n","      cv2.putText(frame,xmin_str, (50, 90),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n","      cv2.putText(frame,xmax_str, (50, 110),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n","      print(scores.max())\n","     \n","      \n","      if scores.max() > 0.78:\n","         print(\"inif\")\n","      if(xmin >= left_boundary[0]):\n","          print(\"move LEFT - 1st !!!\")\n","          cv2.putText(frame,'Move LEFT!', (300, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n","      elif(xmax <= right_boundary[0]):\n","          print(\"move Right - 2nd !!!\")\n","          cv2.putText(frame,'Move RIGHT!', (300, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n","      elif(xmin <= left_boundary[0] and xmax >= right_boundary[0]):\n","          print(\"STOPPPPPP !!!! - 3nd !!!\")\n","          cv2.putText(frame,' STOPPPPPP!!!', (300, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n","      cv2.line(frame,tuple(left_boundary),tuple(left_boundary_top), (255, 0, 0), 5)\n","      cv2.line(frame,tuple(right_boundary),tuple(right_boundary_top), (255, 0, 0), 5)\n","      out.write(frame)\n","except:\n","  pass"],"execution_count":12,"outputs":[{"output_type":"stream","text":["640\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0HhB22u7oVg3"},"source":[""],"execution_count":null,"outputs":[]}]}